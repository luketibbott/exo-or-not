{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "This notebook begins the modeling process for our data set. I will work through several different machine learning algorithms and choose which one is the best based on several metrics including precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keplerutils\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('objects-of-interest.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['rowid', 'kepoi_name', 'pdisposition', 'tce_delivname', 'kepid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['tce_plnt_num'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disposition</th>\n",
       "      <th>period</th>\n",
       "      <th>time0bk</th>\n",
       "      <th>impact</th>\n",
       "      <th>duration</th>\n",
       "      <th>depth</th>\n",
       "      <th>prad</th>\n",
       "      <th>teq</th>\n",
       "      <th>insol</th>\n",
       "      <th>model_snr</th>\n",
       "      <th>steff</th>\n",
       "      <th>slogg</th>\n",
       "      <th>srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.146</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>793.0</td>\n",
       "      <td>93.59</td>\n",
       "      <td>35.8</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638.0</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      disposition     period     time0bk  impact  duration    depth   prad  \\\n",
       "0       CONFIRMED   9.488036  170.538750   0.146   2.95750    615.8   2.26   \n",
       "1       CONFIRMED  54.418383  162.513840   0.586   4.50700    874.8   2.83   \n",
       "2  FALSE POSITIVE  19.899140  175.850252   0.969   1.78220  10829.0  14.60   \n",
       "3  FALSE POSITIVE   1.736952  170.307565   1.276   2.40641   8079.2  33.46   \n",
       "4       CONFIRMED   2.525592  171.595550   0.701   1.65450    603.3   2.75   \n",
       "\n",
       "      teq   insol  model_snr   steff  slogg   srad         ra        dec  \\\n",
       "0   793.0   93.59       35.8  5455.0  4.467  0.927  291.93423  48.141651   \n",
       "1   443.0    9.11       25.8  5455.0  4.467  0.927  291.93423  48.141651   \n",
       "2   638.0   39.30       76.3  5853.0  4.544  0.868  297.00482  48.134129   \n",
       "3  1395.0  891.96      505.6  5805.0  4.564  0.791  285.53461  48.285210   \n",
       "4  1406.0  926.16       40.9  6031.0  4.438  1.046  288.75488  48.226200   \n",
       "\n",
       "   kepmag  \n",
       "0  15.347  \n",
       "1  15.347  \n",
       "2  15.436  \n",
       "3  15.597  \n",
       "4  15.509  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnCV(df):\n",
    "    '''Splits data in to test and training data, 10-fold cross-validates on training data,\n",
    "       calculates scoring metric, and returns the mean of that scoring metric\n",
    "       ----Parameters----\n",
    "       df: Pandas dataframe with response in 0th column, features in rest of columns\n",
    "       ----Returns----\n",
    "       np.mean(scores): the mean of the scores calculated by cross_val_score\n",
    "    ''' \n",
    "    X_train_res, X_test, y_train_res, y_test = keplerutils.split_and_upsample(df)\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "    \n",
    "    tuning_params = {'kneighborsclassifier__n_neighbors': [i for i in range(2, 20)],\n",
    "                     'kneighborsclassifier__weights': ['distance', 'uniform']}\n",
    "    \n",
    "    g = RandomizedSearchCV(pipe, tuning_params, scoring='recall', cv=5)\n",
    "    \n",
    "    g.fit(X_train_res, y_train_res)\n",
    "        \n",
    "    y_preds = g.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print('Accuracy:', accuracy_score(y_test, y_preds))\n",
    "        \n",
    "    print('Best parameters: ', g.best_params_)\n",
    "    \n",
    "    print('Mean grid scores: ', g.cv_results_['mean_test_score'])\n",
    "    \n",
    "    print('Recall score of predictions:', recall_score(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.801762114537445\n",
      "Best parameters:  {'kneighborsclassifier__weights': 'distance', 'kneighborsclassifier__n_neighbors': 8}\n",
      "Mean grid scores:  [0.95615142 0.93028391 0.9555205  0.93564669 0.93217666 0.95457413\n",
      " 0.88864353 0.93659306 0.95362776 0.93943218]\n",
      "Recall score of predictions: 0.6497890295358649\n"
     ]
    }
   ],
   "source": [
    "knnCV(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticCV(df):\n",
    "    '''\n",
    "        Performs logistic regression with 5-fold cross validation on training data and returns \n",
    "        f1 macro score.\n",
    "       ----Parameters----\n",
    "       df: Pandas dataframe with response in 0th column, features in rest of columns\n",
    "       ----Returns----\n",
    "       np.mean(scores): the mean of the scores calculated by GridSearchCV\n",
    "    '''\n",
    "    X_train_res, X_test, y_train_res, y_test = split_and_upsample(df)\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', max_iter=1000))\n",
    "        \n",
    "    tuning_params = {'logisticregression__C': [1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7]}\n",
    "    \n",
    "    g = GridSearchCV(pipe, tuning_params, scoring='f1_macro', cv=5)\n",
    "    \n",
    "    g.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    y_preds = g.predict(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Best parameters: ', g.best_params_)\n",
    "    \n",
    "    print('Mean grid scores: ', g.cv_results_['mean_test_score'])\n",
    "    \n",
    "    y_test = list(map(keplerutils.encode_response, y_test))\n",
    "    y_preds = list(map(keplerutils.encode_response, y_preds))\n",
    "    \n",
    "    print('Accuracy score:', accuracy_score(y_test, y_preds))\n",
    "    \n",
    "    print('F1 score of predictions:', f1_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'logisticregression__C': 10000.0}\n",
      "Mean grid scores:  [0.81229695 0.83325926 0.84806775 0.85236257 0.85431071 0.85746323\n",
      " 0.85789924 0.85740406 0.85740417 0.85757661]\n",
      "Accuracy score: 0.8360254527655409\n",
      "F1 score of predictions: 0.7848426461143224\n"
     ]
    }
   ],
   "source": [
    "logisticCV(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFCCV(df):\n",
    "    '''\n",
    "        Performs Random Forest Classificiation with 5 fold cross validation on training data and\n",
    "        returns f1 macro score.\n",
    "        ----Parameters----\n",
    "       df: Pandas dataframe with response in 0th column, features in rest of columns\n",
    "       ----Returns----\n",
    "       np.mean(scores): the mean of the scores calculated by GridSearchCV\n",
    "    '''\n",
    "    X_train_res, X_test, y_train_res, y_test = keplerutils.split_and_upsample(df)\n",
    "                \n",
    "    pipe = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "        \n",
    "    tuning_params = {'randomforestclassifier__max_depth': [50, 100, 150, 200], \n",
    "                     'randomforestclassifier__n_estimators': [50, 100, 150, 200]}\n",
    "    \n",
    "    g = RandomizedSearchCV(pipe, tuning_params, scoring='f1_macro', cv=5)\n",
    "    \n",
    "    g.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    y_preds = g.predict(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Best parameters: ', g.best_params_)\n",
    "    \n",
    "    print('Mean grid scores: ', g.cv_results_['mean_test_score'])\n",
    "    \n",
    "    print('Accuracy score:', accuracy_score(y_test, y_preds))\n",
    "    \n",
    "    print('F1 score of predictions:', f1_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__max_depth': 100}\n",
      "Mean grid scores:  [0.93924386 0.94098129 0.9393992  0.9403477  0.94209396 0.94145864\n",
      " 0.94098197 0.9406682  0.9411421  0.94161415]\n",
      "Accuracy score: 0.922173274596182\n",
      "F1 score of predictions: 0.8853640951694305\n"
     ]
    }
   ],
   "source": [
    "RFCCV(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
